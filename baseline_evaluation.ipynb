{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PJQe29hsCam",
        "outputId": "51d0189b-eed1-42c0-b306-4157ab758e6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyserini\n",
            "  Downloading pyserini-0.19.1-py3-none-any.whl (130.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 130.5 MB 45 kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from pyserini) (1.7.3)\n",
            "Collecting pyjnius>=1.4.0\n",
            "  Downloading pyjnius-1.4.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 62.0 MB/s \n",
            "\u001b[?25hCollecting onnxruntime>=1.8.1\n",
            "  Downloading onnxruntime-1.13.1-cp38-cp38-manylinux_2_27_x86_64.whl (4.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.5 MB 52.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=3.2.1 in /usr/local/lib/python3.8/dist-packages (from pyserini) (3.4.3)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.8/dist-packages (from pyserini) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from pyserini) (4.64.1)\n",
            "Requirement already satisfied: Cython>=0.29.21 in /usr/local/lib/python3.8/dist-packages (from pyserini) (0.29.32)\n",
            "Collecting nmslib>=2.1.1\n",
            "  Downloading nmslib-2.1.1-cp38-cp38-manylinux2010_x86_64.whl (13.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.4 MB 62.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.8/dist-packages (from pyserini) (1.3.5)\n",
            "Collecting lightgbm>=3.3.2\n",
            "  Downloading lightgbm-3.3.3-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 40.1 MB/s \n",
            "\u001b[?25hCollecting transformers>=4.6.0\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 72.5 MB/s \n",
            "\u001b[?25hCollecting sentencepiece>=0.1.95\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 51.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.8/dist-packages (from pyserini) (1.0.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from lightgbm>=3.3.2->pyserini) (0.38.4)\n",
            "Collecting pybind11<2.6.2\n",
            "  Downloading pybind11-2.6.1-py2.py3-none-any.whl (188 kB)\n",
            "\u001b[K     |████████████████████████████████| 188 kB 55.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from nmslib>=2.1.1->pyserini) (5.4.8)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from onnxruntime>=1.8.1->pyserini) (3.19.6)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.8/dist-packages (from onnxruntime>=1.8.1->pyserini) (1.12)\n",
            "Collecting coloredlogs\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from onnxruntime>=1.8.1->pyserini) (1.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from onnxruntime>=1.8.1->pyserini) (21.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.1.5->pyserini) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.1.5->pyserini) (2022.6)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from pyjnius>=1.4.0->pyserini) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.22.1->pyserini) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.22.1->pyserini) (1.2.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (3.0.8)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (1.0.9)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (2.4.5)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (0.7.0)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (8.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (57.4.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (0.10.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (1.10.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (2.0.8)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (3.3.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (3.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (2.0.7)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (2.23.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (1.0.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.2.1->pyserini) (2.11.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->onnxruntime>=1.8.1->pyserini) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from pathy>=0.3.5->spacy>=3.2.1->pyserini) (5.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy>=3.2.1->pyserini) (4.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (1.24.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy>=3.2.1->pyserini) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy>=3.2.1->pyserini) (0.0.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 69.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.6.0->pyserini) (2022.6.2)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 85.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.6.0->pyserini) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers>=4.6.0->pyserini) (3.8.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy>=3.2.1->pyserini) (7.1.2)\n",
            "Collecting humanfriendly>=9.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 6.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy>=3.2.1->pyserini) (2.0.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->onnxruntime>=1.8.1->pyserini) (1.2.1)\n",
            "Installing collected packages: humanfriendly, tokenizers, pybind11, huggingface-hub, coloredlogs, transformers, sentencepiece, pyjnius, onnxruntime, nmslib, lightgbm, pyserini\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "Successfully installed coloredlogs-15.0.1 huggingface-hub-0.11.1 humanfriendly-10.0 lightgbm-3.3.3 nmslib-2.1.1 onnxruntime-1.13.1 pybind11-2.6.1 pyjnius-1.4.2 pyserini-0.19.1 sentencepiece-0.1.97 tokenizers-0.13.2 transformers-4.25.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.7.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.0 MB 28.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.7.3\n",
            "Cloning into 'anserini'...\n",
            "remote: Enumerating objects: 25150, done.\u001b[K\n",
            "remote: Counting objects: 100% (746/746), done.\u001b[K\n",
            "remote: Compressing objects: 100% (392/392), done.\u001b[K\n",
            "remote: Total 25150 (delta 446), reused 577 (delta 321), pack-reused 24404\u001b[K\n",
            "Receiving objects: 100% (25150/25150), 67.36 MiB | 34.66 MiB/s, done.\n",
            "Resolving deltas: 100% (16184/16184), done.\n",
            "Submodule 'tools' (https://github.com/castorini/anserini-tools.git) registered for path 'tools'\n",
            "Cloning into '/content/anserini/tools'...\n",
            "remote: Enumerating objects: 707, done.        \n",
            "remote: Counting objects: 100% (464/464), done.        \n",
            "remote: Compressing objects: 100% (405/405), done.        \n",
            "remote: Total 707 (delta 68), reused 447 (delta 58), pack-reused 243        \n",
            "Receiving objects: 100% (707/707), 57.74 MiB | 35.47 MiB/s, done.\n",
            "Resolving deltas: 100% (152/152), done.\n",
            "Submodule path 'tools': checked out '95fbaf2af75e2b59304ac5702d5479d50f3bd9ef'\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install pyserini\n",
        "!pip install faiss-cpu\n",
        "\n",
        "!git clone https://github.com/castorini/anserini.git --recurse-submodules"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-Q05fjwvJT7",
        "outputId": "1b1f7949-6805-4412-c27a-0b755dedc4c1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks')"
      ],
      "metadata": {
        "id": "zrthS1g2-akG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install json_lines\n",
        "!pip install jsonlines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDvH5dm6110I",
        "outputId": "c857ef0a-c06f-43c1-99da-af5071a79c9d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting json_lines\n",
            "  Downloading json_lines-0.5.0-py2.py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from json_lines) (1.15.0)\n",
            "Installing collected packages: json-lines\n",
            "Successfully installed json-lines-0.5.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting jsonlines\n",
            "  Downloading jsonlines-3.1.0-py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.8/dist-packages (from jsonlines) (22.1.0)\n",
            "Installing collected packages: jsonlines\n",
            "Successfully installed jsonlines-3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json_lines\n",
        "import jsonlines\n",
        "import csv\n",
        "\n",
        "with open('queries.tsv', 'w', newline='') as f_output:\n",
        "  tsv_w = csv.writer(f_output, delimiter='\\t')\n",
        "  with open('trec-covid/queries.jsonl', 'rb') as f:\n",
        "    for item in json_lines.reader(f):\n",
        "      tsv_w.writerow([item['_id'], item['text']])\n",
        "    f.close()\n",
        "  f_output.close()\n",
        "\n",
        "    \n"
      ],
      "metadata": {
        "id": "Z0BxPeyU2yaP"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = jsonlines.open('corpus/corpus_new.jsonl','w')\n",
        "#i = 0\n",
        "with open('trec-covid/corpus/corpus.jsonl', 'rb') as f:\n",
        "    for item in json_lines.reader(f):\n",
        "      #file = jsonlines.open(f'output/{i}.jsonl','w')\n",
        "      #item[\"id\"] = item.pop(\"_id\")\n",
        "      #item[\"contents\"] = item.pop(\"text\")\n",
        "      item_new = {\"id\": item[\"_id\"], \"contents\": item[\"text\"]}\n",
        "      jsonlines.Writer.write(file,item_new)\n",
        "    f.close()\n",
        "file.close()\n",
        "      #i +=1\n",
        "    "
      ],
      "metadata": {
        "id": "UPzJP7J5IcFA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "outputId": "028d3938-9a12-49e2-fa05-1a4c38e771a1"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-73d52823e7e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#i = 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'trec-covid/corpus/corpus.jsonl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjson_lines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m       \u001b[0;31m#file = jsonlines.open(f'output/{i}.jsonl','w')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0;31m#item[\"id\"] = item.pop(\"_id\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/json_lines/_lib.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_iter_json_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_decode_json_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/json_lines/_lib.py\u001b[0m in \u001b[0;36m_decode_json_line\u001b[0;34m(line)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \"\"\"\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pyserini.index.lucene \\\n",
        "  --collection JsonCollection \\\n",
        "  --input corpus \\\n",
        "  --index indexes/covid_new \\\n",
        "  --generator DefaultLuceneDocumentGenerator \\\n",
        "  --threads 1 \\\n",
        "  --storePositions --storeDocvectors --storeRaw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81XIfeKMsq1b",
        "outputId": "719a7ffc-9062-4bce-a0c7-e913de6e731c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.\n",
            "2022-12-08 17:24:16,500 INFO  [main] index.IndexCollection (IndexCollection.java:250) - Setting log level to INFO\n",
            "2022-12-08 17:24:16,504 INFO  [main] index.IndexCollection (IndexCollection.java:253) - Starting indexer...\n",
            "2022-12-08 17:24:16,504 INFO  [main] index.IndexCollection (IndexCollection.java:254) - ============ Loading Parameters ============\n",
            "2022-12-08 17:24:16,504 INFO  [main] index.IndexCollection (IndexCollection.java:255) - DocumentCollection path: corpus\n",
            "2022-12-08 17:24:16,505 INFO  [main] index.IndexCollection (IndexCollection.java:256) - CollectionClass: JsonCollection\n",
            "2022-12-08 17:24:16,512 INFO  [main] index.IndexCollection (IndexCollection.java:257) - Generator: DefaultLuceneDocumentGenerator\n",
            "2022-12-08 17:24:16,513 INFO  [main] index.IndexCollection (IndexCollection.java:258) - Threads: 1\n",
            "2022-12-08 17:24:16,514 INFO  [main] index.IndexCollection (IndexCollection.java:259) - Language: en\n",
            "2022-12-08 17:24:16,515 INFO  [main] index.IndexCollection (IndexCollection.java:260) - Stemmer: porter\n",
            "2022-12-08 17:24:16,515 INFO  [main] index.IndexCollection (IndexCollection.java:261) - Keep stopwords? false\n",
            "2022-12-08 17:24:16,516 INFO  [main] index.IndexCollection (IndexCollection.java:262) - Stopwords: null\n",
            "2022-12-08 17:24:16,517 INFO  [main] index.IndexCollection (IndexCollection.java:263) - Store positions? true\n",
            "2022-12-08 17:24:16,517 INFO  [main] index.IndexCollection (IndexCollection.java:264) - Store docvectors? true\n",
            "2022-12-08 17:24:16,518 INFO  [main] index.IndexCollection (IndexCollection.java:265) - Store document \"contents\" field? false\n",
            "2022-12-08 17:24:16,519 INFO  [main] index.IndexCollection (IndexCollection.java:266) - Store document \"raw\" field? true\n",
            "2022-12-08 17:24:16,520 INFO  [main] index.IndexCollection (IndexCollection.java:267) - Additional fields to index: []\n",
            "2022-12-08 17:24:16,520 INFO  [main] index.IndexCollection (IndexCollection.java:268) - Optimize (merge segments)? false\n",
            "2022-12-08 17:24:16,529 INFO  [main] index.IndexCollection (IndexCollection.java:269) - Whitelist: null\n",
            "2022-12-08 17:24:16,530 INFO  [main] index.IndexCollection (IndexCollection.java:270) - Pretokenized?: false\n",
            "2022-12-08 17:24:16,530 INFO  [main] index.IndexCollection (IndexCollection.java:271) - Index path: indexes/covid_new\n",
            "2022-12-08 17:24:16,540 INFO  [main] index.IndexCollection (IndexCollection.java:309) - ============ Indexing Collection ============\n",
            "2022-12-08 17:24:18,046 INFO  [main] index.IndexCollection (IndexCollection.java:424) - Thread pool with 1 threads initialized.\n",
            "2022-12-08 17:24:18,047 INFO  [main] index.IndexCollection (IndexCollection.java:426) - Initializing collection in corpus\n",
            "2022-12-08 17:24:18,119 INFO  [main] index.IndexCollection (IndexCollection.java:435) - 1 file found\n",
            "2022-12-08 17:24:18,121 INFO  [main] index.IndexCollection (IndexCollection.java:436) - Starting to index...\n",
            "2022-12-08 17:25:13,272 DEBUG [pool-2-thread-1] index.IndexCollection$LocalIndexerThread (IndexCollection.java:215) - corpus/corpus_new.jsonl: 129192 docs added.\n",
            "2022-12-08 17:25:19,006 INFO  [main] index.IndexCollection (IndexCollection.java:492) - Indexing Complete! 129,192 documents indexed\n",
            "2022-12-08 17:25:19,006 INFO  [main] index.IndexCollection (IndexCollection.java:493) - ============ Final Counter Values ============\n",
            "2022-12-08 17:25:19,006 INFO  [main] index.IndexCollection (IndexCollection.java:494) - indexed:          129,192\n",
            "2022-12-08 17:25:19,006 INFO  [main] index.IndexCollection (IndexCollection.java:495) - unindexable:            0\n",
            "2022-12-08 17:25:19,007 INFO  [main] index.IndexCollection (IndexCollection.java:496) - empty:             42,140\n",
            "2022-12-08 17:25:19,007 INFO  [main] index.IndexCollection (IndexCollection.java:497) - skipped:                0\n",
            "2022-12-08 17:25:19,007 INFO  [main] index.IndexCollection (IndexCollection.java:498) - errors:                 0\n",
            "2022-12-08 17:25:19,013 INFO  [main] index.IndexCollection (IndexCollection.java:501) - Total 129,192 documents indexed in 00:01:02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyserini.search.lucene import LuceneSearcher\n",
        "\n",
        "searcher = LuceneSearcher('indexes/covid_new')\n",
        "hits = searcher.search('document')\n",
        "\n",
        "for i in range(len(hits)):\n",
        "    print(f'{i+1:2} {hits[i].docid:4} {hits[i].score:.5f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1LxR_M_tH0v",
        "outputId": "00e0da06-10b4-45c9-f16e-b364cd31517d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1 mm7gxjf1 3.44140\n",
            " 2 x3o3a45b 3.39030\n",
            " 3 zuc6tmv7 3.36060\n",
            " 4 duxm9u8v 3.35480\n",
            " 5 aw465igx 3.35310\n",
            " 6 q5wglpoj 3.33390\n",
            " 7 hxp258y8 3.31870\n",
            " 8 78dbzxpt 3.28030\n",
            " 9 r7gcdj0j 3.28030\n",
            "10 28xz762w 3.27400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pyserini.search.lucene \\\n",
        "  --index indexes/covid_new \\\n",
        "  --topics queries.tsv \\\n",
        "  --output run.sample.txt \\\n",
        "  --bm25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxdlii-ftc2w",
        "outputId": "37d7dbec-e1b6-46d1-b7d8-f0c2efde8706"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running queries.tsv topics, saving to run.sample.txt...\n",
            "100% 50/50 [00:07<00:00,  6.98it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import math\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "uDnHZVNe5hyJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_qrel_line(line):\n",
        "\n",
        "    lst = line.split()\n",
        "    query = int(lst[0])\n",
        "    document = lst[1]\n",
        "    relevancy = int(lst[2])\n",
        "\n",
        "    return query, document, relevancy"
      ],
      "metadata": {
        "id": "nmZMJMyN5unO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_results_line(line):\n",
        "\n",
        "    lst = line.split()\n",
        "    query = int(lst[0])\n",
        "    document = lst[2]\n",
        "    rank = int(lst[3])\n",
        "\n",
        "    return query, document, rank"
      ],
      "metadata": {
        "id": "3Y3ilctn5zCh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class relevancy_lookup(object):\n",
        "    def __init__(self):\n",
        "        self.relevancies = {}\n",
        "    \n",
        "    def add(self, query, document, relevancy):\n",
        "\n",
        "        if query not in self.relevancies.keys():\n",
        "            self.relevancies.update({query:{document: relevancy}})\n",
        "        else:\n",
        "            self.relevancies[query].update({document: relevancy})\n",
        "\n",
        "        \n",
        "    def get(self, query, document):\n",
        "        if document in self.relevancies[query].keys():\n",
        "            relevancy = self.relevancies[query][document]\n",
        "        else:\n",
        "            relevancy = 0\n",
        "        return relevancy"
      ],
      "metadata": {
        "id": "ApygYkju55YA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ranked_labels(rel_lookup, query, doc_rank_list): \n",
        "    result = np.zeros(len(doc_rank_list), dtype=int)\n",
        "    for x in doc_rank_list:\n",
        "        result[x[1]-1] = rel_lookup.get(query, x[0])\n",
        "    return result"
      ],
      "metadata": {
        "id": "wtkOGQXc5-BC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import islice\n",
        "\n",
        "def process_files(qrel_path, results_path):\n",
        "    relevancies = relevancy_lookup()\n",
        "    with open(qrel_path, 'r') as qrel_file:\n",
        "        next(qrel_file)\n",
        "        for line in qrel_file:\n",
        "            query, document, relevancy = parse_qrel_line(line)\n",
        "            relevancies.add(query, document, relevancy)\n",
        "\n",
        "    with open(results_path, 'r') as results_file:\n",
        "        current_query, document, rank = parse_results_line(next(results_file))    \n",
        "        doc_rank_list = [(document, rank)]\n",
        "        for line in results_file:\n",
        "    \n",
        "            query, document, rank = parse_results_line(line)\n",
        "            # only top 100 be considered\n",
        "            if rank > 100:\n",
        "              continue\n",
        "            \n",
        "            if query != current_query:\n",
        "                yield get_ranked_labels(relevancies, current_query, doc_rank_list)\n",
        "                current_query = query\n",
        "                doc_rank_list = [(document, rank)]\n",
        "            else:\n",
        "                doc_rank_list.append((document, rank))\n",
        "\n",
        "        yield get_ranked_labels(relevancies, current_query, doc_rank_list)"
      ],
      "metadata": {
        "id": "UO31-DQ-6DQV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def precision(query_relevancy_labels, k):\n",
        "    if k > 0:\n",
        "        prec = sum(query_relevancy_labels[:k])/k\n",
        "        #print(prec)\n",
        "        return prec\n",
        "    else:\n",
        "        return 0"
      ],
      "metadata": {
        "id": "jBlIG54L6Nvk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recall(query_relevancy_labels, k):\n",
        "    denominator = sum(query_relevancy_labels)\n",
        "    \n",
        "    if denominator > 0 :\n",
        "        rec = sum(query_relevancy_labels[:k])/denominator\n",
        "        return rec\n",
        "    else:\n",
        "        return 0.0"
      ],
      "metadata": {
        "id": "HjyIpR0G6SNP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def F_score(query_relevancy_labels, k):\n",
        "\n",
        "    denominator = precision(query_relevancy_labels, k) + recall(query_relevancy_labels, k)\n",
        "    \n",
        "    if denominator > 0:\n",
        "        F_s = 2 * precision(query_relevancy_labels, k) * recall(query_relevancy_labels, k)/denominator\n",
        "        return F_s\n",
        "    else:\n",
        "        return 0.0"
      ],
      "metadata": {
        "id": "EXBM1wgB3_RW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def DCG(query_relevancy_labels, k):\n",
        "    # Use log with base 2\n",
        "    lst = []\n",
        "    range_value = min(len(query_relevancy_labels),k)\n",
        "    for i in range(range_value):\n",
        "        denominator = math.log(i+2,2)\n",
        "        \n",
        "        if denominator == 0:\n",
        "            lst.append(0.0)\n",
        "        else:\n",
        "            lst.append(query_relevancy_labels[i]/denominator)\n",
        "    return sum(lst)"
      ],
      "metadata": {
        "id": "tUgXhJwZ6VlZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def NDCG(query_relevancy_labels, k):\n",
        "    max_query_relevancy_labels = abs(np.sort((-1)*query_relevancy_labels))\n",
        "    denominator = DCG(max_query_relevancy_labels, k)\n",
        "    if denominator == 0:\n",
        "        return 0.0\n",
        "    else:\n",
        "        return DCG(query_relevancy_labels, k)/denominator"
      ],
      "metadata": {
        "id": "sh7ETY4u6iyj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def AP(query_relevancy_labels):\n",
        "    denominator = sum(query_relevancy_labels)\n",
        "    if denominator == 0:\n",
        "        return 0.0\n",
        "    else:\n",
        "        lst = []\n",
        "        for k in range(len(query_relevancy_labels)):\n",
        "            lst.append(query_relevancy_labels[k] * precision(query_relevancy_labels[:k+1], k+1))\n",
        "        return sum(lst)/denominator"
      ],
      "metadata": {
        "id": "j90ha3_V6njZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def RR(query_relevancy_labels):\n",
        "\n",
        "    position = list(np.where(query_relevancy_labels == 1)[0])\n",
        "    if position:\n",
        "        return 1/(position[0]+1)\n",
        "    else:\n",
        "        return 0"
      ],
      "metadata": {
        "id": "kqGsXP4L6rTm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(qrel_path, results_path):\n",
        "    results_per_query = {\n",
        "        'precision@1': [],\n",
        "        'precision@5': [],\n",
        "        'precision@10': [],\n",
        "        #'precision@25': [],\n",
        "        'recall@1': [],\n",
        "        'recall@5': [],\n",
        "        'recall@10': [],\n",
        "        #'recall@25': [],\n",
        "        'F-score@1': [],\n",
        "        'F-score@5': [],\n",
        "        'F-score@10': [],\n",
        "        #'F-score@25': [],\n",
        "        'DCG@1': [],\n",
        "        'DCG@5': [],\n",
        "        'DCG@10': [],\n",
        "        #'DCG@25': [],\n",
        "        'NDCG@1': [],\n",
        "        'NDCG@5': [],\n",
        "        'NDCG@10': [],\n",
        "        #'NDCG@25': [],\n",
        "        'MAP': [],\n",
        "        'MRR': [],\n",
        "    }\n",
        "    for labels in process_files(qrel_path, results_path):\n",
        "        results_per_query['precision@1'].append(precision(labels, 1))\n",
        "        results_per_query['precision@5'].append(precision(labels, 5))\n",
        "        results_per_query['precision@10'].append(precision(labels, 10))\n",
        "        #results_per_query['precision@25'].append(precision(labels, 25))\n",
        "        results_per_query['recall@1'].append(recall(labels, 1))\n",
        "        results_per_query['recall@5'].append(recall(labels, 5))\n",
        "        results_per_query['recall@10'].append(recall(labels, 10))\n",
        "        #results_per_query['recall@25'].append(recall(labels, 25))\n",
        "        results_per_query['F-score@1'].append(F_score(labels, 1))\n",
        "        results_per_query['F-score@5'].append(F_score(labels, 5))\n",
        "        results_per_query['F-score@10'].append(F_score(labels, 10))\n",
        "        #results_per_query['F-score@25'].append(F_score(labels, 25))\n",
        "        results_per_query['DCG@1'].append(DCG(labels, 1))\n",
        "        results_per_query['DCG@5'].append(DCG(labels, 5))\n",
        "        results_per_query['DCG@10'].append(DCG(labels, 10))\n",
        "        #results_per_query['DCG@25'].append(DCG(labels, 25))\n",
        "        results_per_query['NDCG@1'].append(NDCG(labels, 1))\n",
        "        results_per_query['NDCG@5'].append(NDCG(labels, 5))\n",
        "        results_per_query['NDCG@10'].append(NDCG(labels, 10))\n",
        "        #results_per_query['NDCG@25'].append(NDCG(labels, 25))\n",
        "        results_per_query['MAP'].append(AP(labels))\n",
        "        results_per_query['MRR'].append(RR(labels))\n",
        "    \n",
        "    results = {}\n",
        "    for key, values in results_per_query.items():\n",
        "        print(key)\n",
        "        print(len(values))\n",
        "        results[key] = np.mean(values)\n",
        "    return results"
      ],
      "metadata": {
        "id": "2mwrpBld62aS"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = evaluate('trec-covid/qrels/test.tsv', 'run.sample.txt')"
      ],
      "metadata": {
        "id": "IEiuYa5FWUTX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1ce2d46-7c4c-448c-a892-55ff3bc207ce"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision@1\n",
            "50\n",
            "precision@5\n",
            "50\n",
            "precision@10\n",
            "50\n",
            "recall@1\n",
            "50\n",
            "recall@5\n",
            "50\n",
            "recall@10\n",
            "50\n",
            "F-score@1\n",
            "50\n",
            "F-score@5\n",
            "50\n",
            "F-score@10\n",
            "50\n",
            "DCG@1\n",
            "50\n",
            "DCG@5\n",
            "50\n",
            "DCG@10\n",
            "50\n",
            "NDCG@1\n",
            "50\n",
            "NDCG@5\n",
            "50\n",
            "NDCG@10\n",
            "50\n",
            "MAP\n",
            "50\n",
            "MRR\n",
            "50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('evaluation_50_query_100_doc.json', 'w') as f:\n",
        "      json.dump(results, f)"
      ],
      "metadata": {
        "id": "lzaBBIRgtBMx"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "OsW-mHXw_hkb"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "with open('output_test_queries.txt', 'r') as qrel_file:\n",
        "  for data in qrel_file:\n",
        "    data = ast.literal_eval(data)\n",
        "    print(data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5z0Wjb_Ah0d",
        "outputId": "1dc37d34-72df-4d4e-fbf5-9f29eeeab5ed"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['kjjljbl5', 0.9798632322702674], ['r3l56awv', 0.9796309719502926], ['1sua5svb', 0.9795677683853861], ['6nmqupmj', 0.9794568498213683], ['13sr3wey', 0.979252744321823], ['txdi3a4v', 0.9792076516127266], ['xxf3qu5v', 0.9791788611286933], ['pkxc2219', 0.9791640402850781], ['qyboryzy', 0.9791474064348326], ['xphxlaat', 0.9790981161281731]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('output_test_queries_formatted.txt', 'w') as f:\n",
        "    lines = ''\n",
        "    count = 0\n",
        "    for item in data:\n",
        "      count += 1\n",
        "      rank = 0\n",
        "      for pair in item:\n",
        "        rank +=1\n",
        "        if rank%10 == 0:\n",
        "          rank = 10\n",
        "        \n",
        "        lines += str(count) + ' ' + 'Q' + ' ' + str(pair[0]) + ' ' + str(rank) + ' ' + str(pair[1]) + '\\n'\n",
        "    f.writelines(lines)"
      ],
      "metadata": {
        "id": "lKp-7BXjBt3t"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('trec-covid/corpus/corpus.jsonl', 'rb') as f:\n",
        "    for item in json_lines.reader(f):\n",
        "      #file = jsonlines.open(f'output/{i}.jsonl','w')\n",
        "      #item[\"id\"] = item.pop(\"_id\")\n",
        "      #item[\"contents\"] = item.pop(\"text\")\n",
        "      #item_new = {\"id\": item[\"_id\"], \"contents\": item[\"text\"]}\n",
        "      #jsonlines.Writer.write(file,item_new)\n",
        "        if item['_id'] == 'kjjljbl5':\n",
        "            print(item)\n",
        "    f.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aX5Lb32fUA3c",
        "outputId": "ccfa1e7a-16f4-486f-80d4-281fc28e3bf3"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'_id': 'kjjljbl5', 'title': 'Existence theory and numerical analysis of three species prey–predator model under Mittag-Leffler power law', 'text': 'In this manuscript, the fractional Atangana–Baleanu–Caputo model of prey and predator is studied theoretically and numerically. The existence and Ulam–Hyers stability results are obtained by applying fixed point theory and nonlinear analysis. The approximation solutions for the considered model are discussed via the fractional Adams Bashforth method. Moreover, the behavior of the solution to the given model is explained by graphical representations through the numerical simulations. The obtained results play an important role in developing the theory of fractional analytical dynamic of many biological systems.', 'metadata': {'url': 'https://doi.org/10.1186/s13662-020-02709-7; https://www.ncbi.nlm.nih.gov/pubmed/32501396/', 'pubmed_id': '32501396'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = evaluate('trec-covid/qrels/test.tsv', 'output_test_queries_formatted.txt')\n",
        "with open('evaluation_test_queries.json', 'w') as f:\n",
        "      json.dump(results, f)"
      ],
      "metadata": {
        "id": "RGLQ2f6UjaZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 新段落"
      ],
      "metadata": {
        "id": "hQUpXztB_rzK"
      }
    }
  ]
}